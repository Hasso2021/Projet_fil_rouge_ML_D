# üöÄ Guide de D√©marrage - Ordre d'Ex√©cution

Guide √©tape par √©tape pour lancer le projet AI Creative Studio dans le bon ordre.

## üìã Vue d'Ensemble

Le projet doit √™tre lanc√© dans cet ordre :

1. **Installation** - D√©pendances et configuration
2. **Test Stable Diffusion** - V√©rifier que la g√©n√©ration fonctionne
3. **Entra√Ænement RL** - Entra√Æner l'agent (sur Colab recommand√©)
4. **Lancement API** - D√©marrer l'API FastAPI
5. **Test API** - V√©rifier que tout fonctionne

---

## üéØ Ordre d'Ex√©cution D√©taill√©

### √âtape 1 : Installation ‚öôÔ∏è

**Dur√©e** : 10-30 minutes

#### 1.1 Cr√©er l'environnement virtuel

```bash
# Cr√©er environnement virtuel
python -m venv .venv

# Activer l'environnement
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate
```

#### 1.2 Installer les d√©pendances

```bash
# Installer toutes les d√©pendances
pip install -r requirements.txt

# OU avec uv (si vous utilisez uv)
uv pip install -r requirements.txt
```

**‚è±Ô∏è Temps estim√©** : 10-20 minutes (t√©l√©chargement de PyTorch, Diffusers, etc.)

**‚ö†Ô∏è Note Python 3.12** : Si vous utilisez Python 3.12, les versions dans requirements.txt sont automatiquement compatibles (PyTorch 2.2+). Pour Python 3.10-3.11, vous pouvez aussi utiliser ces versions.

#### 1.3 Configuration

```bash
# Cr√©er le fichier .env depuis le template
cp env.example .env

# √âditer .env selon votre hardware
# Si CPU:
#   SD_DEVICE=cpu
#   SD_DTYPE=float32
# Si GPU:
#   SD_DEVICE=cuda
#   SD_DTYPE=float16
```

**‚úÖ Validation** : V√©rifier que `.env` existe et contient la bonne configuration

---

### √âtape 2 : Test Stable Diffusion üé®

**Dur√©e** : 2-5 minutes (CPU) ou 30 secondes (GPU)

#### 2.1 Test rapide de g√©n√©ration

```bash
# Cr√©er un script de test simple
python -c "
from app.models.stable_diffusion import sd_generator
print('üîÑ Chargement du mod√®le Stable Diffusion...')
print('‚è±Ô∏è Premi√®re fois: t√©l√©chargement ~4 GB (5-10 min)')
print('üì¶ Mod√®le en cache ensuite')
image = sd_generator.generate(
    prompt='a beautiful sunset, mountains',
    num_inference_steps=25,  # Moins de steps pour test rapide
    width=512,
    height=512
)
print('‚úÖ G√©n√©ration r√©ussie!')
image.save('test_output.png')
print('üíæ Image sauvegard√©e: test_output.png')
"
```

**‚úÖ Validation** : 
- V√©rifier qu'il n'y a pas d'erreur
- V√©rifier que `test_output.png` existe
- Ouvrir l'image pour v√©rifier la qualit√©

**‚ö†Ô∏è Note** : La premi√®re fois, le mod√®le Stable Diffusion sera t√©l√©charg√© (~4 GB, 5-10 minutes)

---

### √âtape 3 : Entra√Ænement RL Agent ü§ñ

**Dur√©e** : 1-2 heures (Colab GPU) ou 20-40 heures (Local CPU)

**üìå IMPORTANT** : Entra√Ænement recommand√© sur **Google Colab** (20-40x plus rapide)

#### Option A : Sur Google Colab (Recommand√©) ‚ö°

1. **Ouvrir le notebook Colab**
   - Aller sur [Google Colab](https://colab.research.google.com/)
   - Upload `notebooks/colab_train_rl.ipynb`
   - **OU** cloner votre repo directement dans Colab

2. **Activer GPU**
   - `Runtime > Change runtime type > GPU (T4 ou V100)`

3. **Modifier l'URL du repo** (si clonage)
   ```python
   REPO_URL = "https://github.com/VOTRE-USER/VOTRE-REPO.git"
   ```

4. **Ex√©cuter toutes les cellules**
   - Installation des d√©pendances
   - Entra√Ænement RL (10k steps = ~1-2h)
   - T√©l√©chargement du mod√®le

5. **T√©l√©charger le mod√®le**
   - Le notebook t√©l√©charge automatiquement `rl_agent.zip`
   - Placer le fichier dans `models/rl_agent.zip` de votre projet local

**‚úÖ Validation** : V√©rifier que `models/rl_agent.zip` existe (~10-50 MB)

#### Option B : Local (CPU) üêå

```bash
# Entra√Ænement local (TR√àS LENT sur CPU)
python training/train_rl_agent.py --total_timesteps 10000

# ‚ö†Ô∏è ATTENTION: 20-40 heures sur CPU
```

**üí° Recommandation** : Utiliser Colab pour l'entra√Ænement, m√™me si vous ex√©cutez l'API localement.

---

### √âtape 4 : Test de l'Agent RL üß™

**Dur√©e** : 2-5 minutes

```bash
# Tester que l'agent fonctionne
python training/evaluate_agent.py --prompt "a cat" --n_iterations 5

# V√©rifier les r√©sultats:
# - Prompt original vs optimis√©
# - Score original vs optimis√©
# - Am√©lioration mesur√©e
```

**‚úÖ Validation** : V√©rifier que l'optimisation fonctionne et am√©liore le score

---

### √âtape 5 : Lancement de l'Interface Gradio üöÄ

**Dur√©e** : Instantan√© (d√©marrage)

```bash
# Lancer l'interface Gradio interactive (RECOMMAND√â)
python run_gradio.py

# OU directement
python -m app.gradio_ui
```

**‚úÖ Validation** :
- Interface accessible sur `http://localhost:7860`
- Interface web interactive avec g√©n√©ration d'images
- Visualisation directe des r√©sultats
- Optimisation RL int√©gr√©e

**‚ö†Ô∏è Note** : L'interface chargera automatiquement :
- Stable Diffusion au d√©marrage (~4 GB en m√©moire si GPU)
- Agent RL depuis `models/rl_agent.zip` (si disponible)

### √âtape 5bis : Lancer l'API FastAPI (Optionnel) üåê

Si vous pr√©f√©rez utiliser l'API REST au lieu de Gradio :

```bash
# Lancer l'API FastAPI
python -m app.main

# OU avec uvicorn directement
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

**‚úÖ Validation** :
- API accessible sur `http://localhost:8000`
- Documentation Swagger : `http://localhost:8000/docs`
- Health check : `http://localhost:8000/api/v1/health`

---

### √âtape 6 : Test de l'Interface Gradio üß™

**Dur√©e** : 2 minutes

#### 6.1 Ouvrir l'interface

1. Ouvrir votre navigateur
2. Aller sur `http://localhost:7860`
3. Vous devriez voir l'interface Gradio avec plusieurs onglets

#### 6.2 Test G√©n√©ration Simple

1. **Onglet "G√©n√©ration d'Images"**
2. Entrer un prompt : `a beautiful landscape with mountains`
3. Cocher ou d√©cocher "Utiliser optimisation RL" (selon disponibilit√© du mod√®le)
4. Ajuster les param√®tres si n√©cessaire (steps, guidance scale, etc.)
5. Cliquer sur "üé® G√©n√©rer"
6. Attendre la g√©n√©ration (~3-5 minutes sur CPU, ~10-30s sur GPU)

**‚úÖ Validation** : 
- V√©rifier que l'image appara√Æt dans la zone de sortie
- V√©rifier les informations (score, temps de g√©n√©ration, etc.)
- V√©rifier que l'image est sauvegard√©e dans `outputs/portfolio/`

#### 6.3 Test Optimisation RL (si mod√®le entra√Æn√©)

1. **Onglet "ü§ñ Optimisation RL"**
2. Entrer un prompt simple : `a cat`
3. Ajuster le nombre d'it√©rations (10 recommand√©)
4. Cliquer sur "üöÄ Optimiser"
5. Attendre les r√©sultats

**‚úÖ Validation** : 
- V√©rifier que le prompt optimis√© est diff√©rent du prompt original
- V√©rifier l'am√©lioration du score
- V√©rifier les param√®tres optimaux recommand√©s

#### 6.4 Test G√©n√©ration avec RL

1. **Onglet "G√©n√©ration d'Images"**
2. Entrer un prompt simple : `a cat`
3. **Cocher "Utiliser optimisation RL"**
4. Cliquer sur "üé® G√©n√©rer"

**‚úÖ Validation** : 
- V√©rifier que le prompt optimis√© est affich√© dans les informations
- V√©rifier l'am√©lioration du score
- V√©rifier que l'image est g√©n√©r√©e

### √âtape 6bis : Test de l'API FastAPI (si utilis√©e) üåê

Si vous utilisez l'API FastAPI au lieu de Gradio :

```bash
# Health check
curl http://localhost:8000/api/v1/health

# G√©n√©ration simple
curl -X POST "http://localhost:8000/api/v1/generate" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "a beautiful landscape", "num_inference_steps": 25}'
```

---

## üìä R√©sum√© de l'Ordre

| √âtape | Action | Dur√©e | Obligatoire |
|-------|--------|-------|-------------|
| **1** | Installation d√©pendances | 10-30 min | ‚úÖ Oui |
| **2** | Test Stable Diffusion | 30s-5min | ‚úÖ Oui |
| **3** | Entra√Ænement RL Agent | 1-2h (Colab) | ‚úÖ Oui |
| **4** | Test Agent RL | 2-5 min | ‚ö†Ô∏è Recommand√© |
| **5** | Lancement API | Instantan√© | ‚úÖ Oui |
| **6** | Test API | 2 min | ‚ö†Ô∏è Recommand√© |

---

## üîÑ Workflow Recommand√© par Sprint

### Sprint 1 : GenAI (D√©veloppement Local)

```bash
# 1. Installation
pip install -r requirements.txt
cp env.example .env

# 2. Test Stable Diffusion
python -c "from app.models.stable_diffusion import sd_generator; \
           image = sd_generator.generate(prompt='test', num_inference_steps=25); \
           image.save('test.png')"

# 3. Lancement API
python -m app.main

# 4. Test API (sans RL)
curl -X POST "http://localhost:8000/api/v1/generate" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "a landscape"}'
```

**Pas besoin d'agent RL pour Sprint 1**

---

### Sprint 2 : RL Agent (Entra√Ænement Colab)

1. **Sur Colab** : Entra√Æner l'agent (`notebooks/colab_train_rl.ipynb`)
2. **T√©l√©charger** : `models/rl_agent.zip`
3. **Placer** : Dans `models/rl_agent.zip` du projet local
4. **Tester** : `python training/evaluate_agent.py --prompt "test"`

---

### Sprint 3-4 : D√©ploiement (Local)

```bash
# 1. V√©rifier que le mod√®le RL existe
ls -lh models/rl_agent.zip

# 2. Lancer l'API (avec mod√®le RL pr√©-entra√Æn√©)
python -m app.main

# 3. Test complet avec RL
curl -X POST "http://localhost:8000/api/v1/generate" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "a cat", "use_rl_optimization": true}'

# 4. Docker (optionnel)
docker build -t ai-creative-studio .
docker run -p 8000:8000 ai-creative-studio
```

---

## ‚ö†Ô∏è Erreurs Courantes

### Probl√®me : Mod√®le Stable Diffusion non trouv√©

**Solution** :
```bash
# V√©rifier que le cache Hugging Face existe
# Le mod√®le sera t√©l√©charg√© automatiquement au premier usage
# Cache: ~/.cache/huggingface/hub/
```

### Probl√®me : Agent RL non trouv√©

**Solution** :
```bash
# V√©rifier que le mod√®le existe
ls -lh models/rl_agent.zip

# Si absent, entra√Æner d'abord (√âtape 3)
# ou t√©l√©charger depuis Colab
```

### Probl√®me : Out of Memory

**Solution** :
```bash
# Dans .env:
SD_DEVICE=cpu
SD_DTYPE=float32

# Ou r√©duire la r√©solution:
width=384
height=384
```

### Probl√®me : API ne d√©marre pas

**Solution** :
```bash
# V√©rifier que le port 8000 n'est pas utilis√©
# Windows:
netstat -ano | findstr :8000
# Linux/Mac:
lsof -i :8000

# Utiliser un autre port:
uvicorn app.main:app --port 8001
```

---

## ‚úÖ Checklist de D√©marrage

- [ ] Environnement virtuel cr√©√© et activ√©
- [ ] D√©pendances install√©es (`pip install -r requirements.txt`)
- [ ] Fichier `.env` cr√©√© depuis `env.example`
- [ ] Stable Diffusion test√© et fonctionnel
- [ ] Agent RL entra√Æn√© (`models/rl_agent.zip` existe)
- [ ] Agent RL test√© et fonctionnel
- [ ] API lanc√©e et accessible sur `http://localhost:8000`
- [ ] Tests API r√©ussis (health, generate, optimize)

---

## üìö Ressources

- **Guide workflow hybride** : `WORKFLOW_HYBRIDE.md`
- **Documentation API** : `http://localhost:8000/docs`
- **README principal** : `README.md`

---

**üéØ Une fois toutes les √©tapes compl√©t√©es, votre projet est pr√™t ! üöÄ**

