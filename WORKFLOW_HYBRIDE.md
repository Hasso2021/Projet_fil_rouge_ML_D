# ğŸ”„ Workflow Hybride : EntraÃ®nement Colab + ExÃ©cution Locale

Guide pour **entraÃ®ner l'agent RL sur Google Colab** et **utiliser le modÃ¨le localement**.

## ğŸ¯ StratÃ©gie

1. **EntraÃ®nement RL** : Google Colab (GPU gratuit, rapide)
2. **TÃ©lÃ©chargement modÃ¨le** : Depuis Colab vers local
3. **ExÃ©cution API** : Localement avec modÃ¨le prÃ©-entraÃ®nÃ©

## ğŸ“‹ Workflow Complet

### Phase 1 : EntraÃ®nement sur Colab (Sprint 2)

#### Ã‰tape 1 : Ouvrir le notebook Colab

1. Aller sur [Google Colab](https://colab.research.google.com/)
2. Ouvrir le notebook : `notebooks/colab_train_rl.ipynb`
3. **Activer GPU** : `Runtime > Change runtime type > GPU (T4 ou V100)`

#### Ã‰tape 2 : Configurer le repository

Dans le notebook, modifier :
```python
REPO_URL = "https://github.com/VOTRE-USER/VOTRE-REPO.git"
```

#### Ã‰tape 3 : Lancer l'entraÃ®nement

ExÃ©cuter toutes les cellules. L'entraÃ®nement prendra :
- **10k steps** : ~1-2 heures
- **20k steps** : ~2-4 heures

#### Ã‰tape 4 : TÃ©lÃ©charger le modÃ¨le

**Option A : TÃ©lÃ©chargement direct**
- La derniÃ¨re cellule du notebook tÃ©lÃ©charge automatiquement `rl_agent.zip`
- Cliquer sur le fichier tÃ©lÃ©chargÃ© et le placer dans `models/rl_agent.zip`

**Option B : Google Drive**
- Le modÃ¨le est automatiquement sauvegardÃ© dans Drive
- TÃ©lÃ©charger depuis `ai-creative-studio/models/rl_agent.zip`

### Phase 2 : Utilisation Locale (Sprints 1, 3, 4)

#### Ã‰tape 1 : Placer le modÃ¨le

```bash
# VÃ©rifier que le modÃ¨le est au bon endroit
ls -lh models/rl_agent.zip

# Le chemin doit correspondre Ã  celui dans .env
# RL_AGENT_PATH=models/rl_agent.zip
```

#### Ã‰tape 2 : Configurer le projet local

```bash
# CrÃ©er .env
cp env.example .env

# Modifier .env pour CPU (si pas de GPU)
# SD_DEVICE=cpu
# SD_DTYPE=float32
```

#### Ã‰tape 3 : Lancer l'API

```bash
# Lancer l'API
python -m app.main

# Ou avec uvicorn
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

#### Ã‰tape 4 : Utiliser le modÃ¨le entraÃ®nÃ©

L'API chargera automatiquement le modÃ¨le depuis `models/rl_agent.zip` si disponible.

```bash
# GÃ©nÃ©ration avec optimisation RL
curl -X POST "http://localhost:8000/api/v1/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "a beautiful landscape",
    "use_rl_optimization": true
  }'
```

## ğŸ“Š Comparaison Temps d'EntraÃ®nement

| Steps | Colab (GPU) | Local (CPU) |
|-------|-------------|-------------|
| 1k | ~10-15 min | ~2-4 heures |
| 10k | ~1-2 heures | **20-40 heures** |
| 20k | ~2-4 heures | **40-80 heures** |

**ğŸ’¡ Gain de temps : 20-40x plus rapide sur Colab !**

## ğŸ”„ Workflow Par Sprint

### Sprint 1 : GenAI (Local)
- âœ… DÃ©veloppement local de l'API
- âœ… Tests de gÃ©nÃ©ration d'images
- âœ… Pas besoin de modÃ¨le RL encore

### Sprint 2 : RL Agent (Colab)
- âœ… EntraÃ®nement sur Colab (`colab_train_rl.ipynb`)
- âœ… TÃ©lÃ©chargement du modÃ¨le
- âœ… Test rapide sur Colab (optionnel)

### Sprint 3 : DÃ©ploiement (Local)
- âœ… Utilisation du modÃ¨le prÃ©-entraÃ®nÃ©
- âœ… API locale avec Docker
- âœ… DÃ©monstration

### Sprint 4 : Finalisation (Local)
- âœ… Utilisation du modÃ¨le dans l'API
- âœ… Portfolio de gÃ©nÃ©rations
- âœ… PrÃ©sentation

## ğŸ“ Structure des Fichiers

```
Projet_fil_rouge_ML_DL/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ rl_agent.zip          # â† ModÃ¨le tÃ©lÃ©chargÃ© depuis Colab
â”‚   â””â”€â”€ checkpoints/          # Checkpoints d'entraÃ®nement (optionnel)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ colab_train_rl.ipynb  # â† Notebook pour entraÃ®nement Colab
â”œâ”€â”€ app/
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ rl_agent.py       # Charge le modÃ¨le depuis models/rl_agent.zip
â””â”€â”€ .env                      # RL_AGENT_PATH=models/rl_agent.zip
```

## âœ… Checklist

### Avant EntraÃ®nement Colab
- [ ] Notebook `colab_train_rl.ipynb` prÃªt
- [ ] GPU activÃ© dans Colab
- [ ] Repository GitHub clonable (ou code uploadÃ©)
- [ ] ~2-4 heures disponibles pour l'entraÃ®nement

### AprÃ¨s EntraÃ®nement Colab
- [ ] ModÃ¨le `rl_agent.zip` tÃ©lÃ©chargÃ©
- [ ] ModÃ¨le placÃ© dans `models/rl_agent.zip` localement
- [ ] Taille du modÃ¨le vÃ©rifiÃ©e (~10-50 MB)
- [ ] ModÃ¨le sauvegardÃ© dans Drive (backup)

### Avant Utilisation Locale
- [ ] Fichier `.env` configurÃ©
- [ ] `RL_AGENT_PATH=models/rl_agent.zip` dans `.env`
- [ ] API testÃ©e sans optimisation RL
- [ ] ModÃ¨le testÃ© avec optimisation RL

## ğŸ”§ DÃ©pannage

### ProblÃ¨me : ModÃ¨le non trouvÃ© localement

**VÃ©rifier le chemin** :
```bash
# VÃ©rifier que le fichier existe
ls -lh models/rl_agent.zip

# VÃ©rifier le chemin dans .env
cat .env | grep RL_AGENT_PATH
```

### ProblÃ¨me : Erreur lors du chargement

**VÃ©rifier la compatibilitÃ©** :
- Le modÃ¨le doit Ãªtre entraÃ®nÃ© avec la mÃªme version de stable-baselines3
- VÃ©rifier dans `requirements.txt` : `stable-baselines3==2.2.1`

### ProblÃ¨me : ModÃ¨le trop gros pour Drive

**Compression** :
```python
# Dans Colab, compresser avant upload
import zipfile
import os

model_path = "models/rl_agent.zip"
if os.path.exists(model_path):
    # VÃ©rifier taille
    size_mb = os.path.getsize(model_path) / (1024 * 1024)
    print(f"Taille: {size_mb:.2f} MB")
    
    # Si > 100 MB, considÃ©rer utiliser GitHub Releases ou Drive Pro
```

## ğŸ’¡ Astuces

1. **Backup multiple** : Sauvegarder dans Drive ET tÃ©lÃ©charger directement
2. **Versioning** : Nommer le modÃ¨le avec timestamp : `rl_agent_20250119.zip`
3. **Checkpoints** : Sauvegarder aussi les checkpoints intermÃ©diaires
4. **Tests** : Tester le modÃ¨le sur Colab avant tÃ©lÃ©chargement

## ğŸ“š Ressources

- **Notebook Colab** : `notebooks/colab_train_rl.ipynb`
- **Code Agent RL** : `app/models/rl_agent.py`
- **Configuration** : `.env` et `env.example`

---

**ğŸ¯ RÃ©sultat : EntraÃ®nement rapide sur Colab + ExÃ©cution locale confortable !**

