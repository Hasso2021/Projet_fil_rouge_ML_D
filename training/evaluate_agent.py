"""
Script pour √©valuer l'agent RL entra√Æn√©.
"""
import argparse
from app.models.rl_agent import RLOptimizer
from training.rl_env import PromptOptimizationEnv

def main():
    parser = argparse.ArgumentParser(description="√âvaluer l'agent RL")
    parser.add_argument(
        "--prompt",
        type=str,
        default="a beautiful landscape",
        help="Prompt de base √† optimiser"
    )
    parser.add_argument(
        "--n_iterations",
        type=int,
        default=10,
        help="Nombre d'it√©rations d'optimisation"
    )
    
    args = parser.parse_args()
    
    # Cr√©er environnement et agent
    env = PromptOptimizationEnv()
    agent = RLOptimizer(env=env)
    
    if agent.model is None:
        print("‚ùå Erreur: Mod√®le RL non trouv√©. Entra√Ænez d'abord avec train_rl_agent.py")
        return
    
    # Optimiser le prompt
    print(f"üîÑ Optimisation du prompt: '{args.prompt}'...")
    result = agent.optimize_prompt(
        base_prompt=args.prompt,
        n_iterations=args.n_iterations
    )
    
    # Afficher r√©sultats
    print("\nüìä R√©sultats de l'optimisation:")
    print(f"  Prompt original: {result['original_prompt']}")
    print(f"  Prompt optimis√©: {result['optimized_prompt']}")
    print(f"  Score original: {result['original_score']:.2f}")
    print(f"  Score optimis√©: {result['optimized_score']:.2f}")
    print(f"  Am√©lioration: {result['improvement']:+.2f}")
    print(f"  Param√®tres optimaux: {result['best_params']}")

if __name__ == "__main__":
    main()

