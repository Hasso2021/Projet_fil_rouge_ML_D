# ðŸ¤– Guide : EntraÃ®ner l'Agent RL sur Google Colab

Guide Ã©tape par Ã©tape pour entraÃ®ner votre agent RL sur Google Colab avec GPU gratuit.

## ðŸŽ¯ Pourquoi Google Colab ?

- âœ… **GPU gratuit** (T4 ou V100) - 20-40x plus rapide que CPU
- âœ… **Pas d'installation** - Tout fonctionne dans le navigateur
- âœ… **1-2 heures** pour 10k steps (vs 20-40h sur CPU local)

---

## ðŸ“‹ Ã‰tapes DÃ©taillÃ©es

### Ã‰tape 1 : PrÃ©parer votre projet sur GitHub

**âš ï¸ IMPORTANT** : Votre projet doit Ãªtre sur GitHub pour que Colab puisse le cloner.

1. **CrÃ©er un repository GitHub** (si pas dÃ©jÃ  fait)
   - Aller sur [GitHub](https://github.com)
   - CrÃ©er un nouveau repository
   - Uploader votre code

2. **Noter l'URL du repository**
   - Exemple : `https://github.com/votre-username/votre-repo.git`

---

### Ã‰tape 2 : Ouvrir Google Colab

1. Aller sur [Google Colab](https://colab.research.google.com/)
2. Se connecter avec votre compte Google
3. Cliquer sur **"Nouveau notebook"** ou **"File > New notebook"**

---

### Ã‰tape 3 : Uploader le notebook

**Option A : Depuis votre ordinateur**
1. Dans Colab : **File > Upload notebook**
2. SÃ©lectionner `notebooks/colab_train_rl.ipynb` de votre projet local

**Option B : CrÃ©er un nouveau notebook**
1. CrÃ©er un nouveau notebook dans Colab
2. Copier-coller le contenu des cellules (voir ci-dessous)

---

### Ã‰tape 4 : Activer le GPU

**âš ï¸ CRUCIAL** : Sans GPU, l'entraÃ®nement sera trÃ¨s lent !

1. Dans Colab : **Runtime > Change runtime type**
2. SÃ©lectionner :
   - **Hardware accelerator** : **GPU**
   - **GPU type** : **T4** (gratuit) ou **V100** (si disponible)
3. Cliquer sur **"Save"**

---

### Ã‰tape 5 : ExÃ©cuter les cellules du notebook

Le notebook `colab_train_rl.ipynb` contient toutes les Ã©tapes. ExÃ©cutez-les dans l'ordre :

#### Cellule 1 : Installation des dÃ©pendances

```python
# Installation PyTorch avec CUDA 11.8 (pour GPU Colab)
%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118 -q

# DÃ©pendances principales pour RL
%pip install diffusers transformers accelerate -q
%pip install stable-baselines3[extra] gymnasium -q
%pip install pillow numpy requests pydantic pydantic-settings -q

print("âœ… DÃ©pendances installÃ©es")
```

**â±ï¸ Temps** : 2-5 minutes

#### Cellule 2 : Cloner votre repository

```python
# âš ï¸ MODIFIER CETTE URL avec votre repository GitHub
REPO_URL = "https://github.com/VOTRE-USERNAME/VOTRE-REPO.git"

import os

# Cloner le repo
if not os.path.exists("Projet_fil_rouge_ML_DL"):
    !git clone {REPO_URL}

%cd Projet_fil_rouge_ML_DL

# Configuration pour Colab (GPU)
os.environ["SD_DEVICE"] = "cuda"
os.environ["SD_DTYPE"] = "float16"
os.environ["OUTPUT_DIR"] = "outputs"
os.environ["MODELS_DIR"] = "models"
os.environ["RL_AGENT_PATH"] = "models/rl_agent.zip"

print("âœ… Projet configurÃ©")
```

**âš ï¸ IMPORTANT** : Remplacer `REPO_URL` par l'URL de votre repository GitHub !

**â±ï¸ Temps** : 30 secondes

#### Cellule 3 : VÃ©rifier le GPU

```python
!nvidia-smi

import torch
print(f"âœ… PyTorch version: {torch.__version__}")
print(f"âœ… CUDA disponible: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
    print(f"âœ… MÃ©moire GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
else:
    print("\nâŒ ERREUR: Aucun GPU dÃ©tectÃ©!")
```

**âœ… VÃ©rification** : Vous devriez voir "CUDA disponible: True" et le nom du GPU

#### Cellule 4 : EntraÃ®ner l'agent RL

```python
# Configuration de l'entraÃ®nement
TOTAL_TIMESTEPS = 10000  # Ajustez selon vos besoins
SAVE_PATH = "models/rl_agent.zip"

print(f"ðŸš€ DÃ©marrage entraÃ®nement RL agent...")
print(f"ðŸ“Š Steps d'entraÃ®nement: {TOTAL_TIMESTEPS}")
print(f"â±ï¸ Temps estimÃ©: {TOTAL_TIMESTEPS // 5000:.1f}-{TOTAL_TIMESTEPS // 2500:.1f} heures")
print("\n" + "="*50 + "\n")

# Importer les modules
from app.models.rl_agent import RLOptimizer
from training.rl_env import PromptOptimizationEnv

# CrÃ©er environnement et agent
env = PromptOptimizationEnv()
agent = RLOptimizer(env=env)

# EntraÃ®ner l'agent
agent.train(
    total_timesteps=TOTAL_TIMESTEPS,
    save_path=SAVE_PATH
)

print("\n" + "="*50)
print("âœ… EntraÃ®nement terminÃ© !")
print(f"ðŸ“¦ ModÃ¨le sauvegardÃ©: {SAVE_PATH}")
```

**â±ï¸ Temps** : 
- **10k steps** : ~1-2 heures
- **20k steps** : ~2-4 heures

**ðŸ’¡ Astuce** : Commencez avec 1000-2000 steps pour tester rapidement, puis augmentez.

#### Cellule 5 : VÃ©rifier le modÃ¨le

```python
import os
model_path = "models/rl_agent.zip"

if os.path.exists(model_path):
    size_mb = os.path.getsize(model_path) / (1024 * 1024)
    print(f"âœ… ModÃ¨le trouvÃ©: {model_path}")
    print(f"ðŸ“¦ Taille: {size_mb:.2f} MB")
else:
    print(f"âŒ ERREUR: ModÃ¨le non trouvÃ©")
```

#### Cellule 6 : TÃ©lÃ©charger le modÃ¨le

**Option A : TÃ©lÃ©chargement direct**

```python
from google.colab import files

model_path = "models/rl_agent.zip"
if os.path.exists(model_path):
    print(f"ðŸ“¥ TÃ©lÃ©chargement de {model_path}...")
    files.download(model_path)
    print("âœ… TÃ©lÃ©chargement terminÃ© !")
    print("\nðŸ’¡ Placez le fichier dans le dossier 'models/' de votre projet local")
else:
    print(f"âŒ ModÃ¨le non trouvÃ©: {model_path}")
```

**Option B : Sauvegarder dans Google Drive**

```python
from google.colab import drive
drive.mount('/content/drive')

# CrÃ©er dossier de sauvegarde
DRIVE_MODELS_DIR = "/content/drive/MyDrive/ai-creative-studio/models"
os.makedirs(DRIVE_MODELS_DIR, exist_ok=True)

# Copier le modÃ¨le vers Drive
!cp models/rl_agent.zip {DRIVE_MODELS_DIR}/rl_agent.zip

print(f"âœ… ModÃ¨le sauvegardÃ© dans Google Drive")
print(f"ðŸ“¦ Chemin: {DRIVE_MODELS_DIR}/rl_agent.zip")
```

---

## ðŸ“¥ Ã‰tape 6 : RÃ©cupÃ©rer le modÃ¨le localement

### Option A : TÃ©lÃ©chargement direct depuis Colab

1. ExÃ©cuter la cellule de tÃ©lÃ©chargement
2. Le fichier `rl_agent.zip` sera tÃ©lÃ©chargÃ© automatiquement
3. Placer le fichier dans `models/rl_agent.zip` de votre projet local

### Option B : Depuis Google Drive

1. Aller sur [Google Drive](https://drive.google.com)
2. Naviguer vers `ai-creative-studio/models/`
3. TÃ©lÃ©charger `rl_agent.zip`
4. Placer dans `models/rl_agent.zip` de votre projet local

---

## âœ… Ã‰tape 7 : VÃ©rifier localement

```bash
# VÃ©rifier que le modÃ¨le existe
ls -lh models/rl_agent.zip

# Le fichier devrait faire ~10-50 MB
```

---

## ðŸ§ª Test rapide (optionnel sur Colab)

Avant de tÃ©lÃ©charger, vous pouvez tester le modÃ¨le :

```python
# Test rapide d'optimisation
test_prompt = "a cat"

result = agent.optimize_prompt(
    base_prompt=test_prompt,
    n_iterations=5
)

print(f"Prompt original: {result['original_prompt']}")
print(f"Prompt optimisÃ©: {result['optimized_prompt']}")
print(f"AmÃ©lioration: {result['improvement']:+.2f}")
```

---

## âš ï¸ Points d'Attention

### 1. Session Colab limitÃ©e

- **Gratuit** : 12 heures max par session
- **Colab Pro** : 24 heures max
- **Solution** : Sauvegarder rÃ©guliÃ¨rement dans Drive

### 2. GPU indisponible

Parfois pas de GPU disponible :
- Attendre quelques minutes
- RÃ©essayer plus tard
- Utiliser Colab Pro (plus de GPU disponibles)

### 3. Interruption de session

Si la session s'interrompt :
- Les checkpoints sont sauvegardÃ©s dans `models/checkpoints/`
- Vous pouvez reprendre l'entraÃ®nement depuis un checkpoint
- Le modÃ¨le final est dans `models/rl_agent.zip`

### 4. Taille du modÃ¨le

Le modÃ¨le fait ~10-50 MB, facilement tÃ©lÃ©chargeable.

---

## ðŸ“Š ParamÃ¨tres d'EntraÃ®nement RecommandÃ©s

| Objectif | Steps | Temps estimÃ© | QualitÃ© |
|---------|-------|--------------|---------|
| **Test rapide** | 1,000 | ~10-15 min | Basique |
| **Minimum viable** | 5,000 | ~30-60 min | Acceptable |
| **RecommandÃ©** | 10,000 | ~1-2 heures | Bon |
| **Optimal** | 20,000 | ~2-4 heures | Excellent |

**ðŸ’¡ Pour le projet** : 10,000 steps est un bon compromis.

---

## ðŸ”„ Reprendre un EntraÃ®nement

Si l'entraÃ®nement est interrompu, vous pouvez reprendre :

```python
# Charger depuis un checkpoint
from stable_baselines3 import PPO
from training.rl_env import PromptOptimizationEnv

env = PromptOptimizationEnv()
# Charger le dernier checkpoint
agent.model = PPO.load("models/checkpoints/ppo_prompt_opt_5000_steps.zip", env=env)

# Continuer l'entraÃ®nement
agent.train(total_timesteps=5000, save_path="models/rl_agent.zip")
```

---

## ðŸ“ Checklist ComplÃ¨te

### Avant de commencer
- [ ] Projet uploadÃ© sur GitHub
- [ ] URL du repository notÃ©e
- [ ] Notebook Colab ouvert
- [ ] GPU activÃ© dans Colab

### Pendant l'entraÃ®nement
- [ ] DÃ©pendances installÃ©es
- [ ] Repository clonÃ©
- [ ] GPU vÃ©rifiÃ©
- [ ] EntraÃ®nement lancÃ©
- [ ] Progression surveillÃ©e

### AprÃ¨s l'entraÃ®nement
- [ ] ModÃ¨le vÃ©rifiÃ© (taille ~10-50 MB)
- [ ] ModÃ¨le tÃ©lÃ©chargÃ© ou sauvegardÃ© dans Drive
- [ ] ModÃ¨le placÃ© dans `models/rl_agent.zip` localement
- [ ] TestÃ© localement

---

## ðŸ†˜ DÃ©pannage

### ProblÃ¨me : "No module named 'app'"

**Solution** : VÃ©rifier que vous Ãªtes dans le bon rÃ©pertoire
```python
%cd Projet_fil_rouge_ML_DL
import os
print(os.getcwd())  # Devrait afficher .../Projet_fil_rouge_ML_DL
```

### ProblÃ¨me : GPU non disponible

**Solution** :
1. Attendre quelques minutes
2. RÃ©essayer
3. Utiliser Colab Pro

### ProblÃ¨me : Out of Memory

**Solution** : RÃ©duire les paramÃ¨tres d'entraÃ®nement
```python
# Dans training/rl_env.py ou agent, rÃ©duire batch_size
agent.model = PPO(
    "MlpPolicy",
    env,
    batch_size=32,  # Au lieu de 64
    n_steps=1024,   # Au lieu de 2048
)
```

### ProblÃ¨me : EntraÃ®nement trÃ¨s lent

**VÃ©rifier** :
- GPU activÃ© : `Runtime > Change runtime type > GPU`
- CUDA disponible : `torch.cuda.is_available()` doit Ãªtre `True`

---

## ðŸ“š Ressources

- **Notebook Colab** : `notebooks/colab_train_rl.ipynb`
- **Workflow hybride** : `WORKFLOW_HYBRIDE.md`
- **Documentation Stable-Baselines3** : https://stable-baselines3.readthedocs.io/

---

**ðŸŽ¯ Une fois le modÃ¨le tÃ©lÃ©chargÃ©, vous pouvez l'utiliser localement dans votre API ou interface Gradio !**

